{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(968, 110)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import kagglegym\n",
    "\n",
    "# Create environment\n",
    "env = kagglegym.make()\n",
    "# Get first observation\n",
    "observation = env.reset()\n",
    "\n",
    "observation.features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[110, 36]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hyperparameters\n",
    "batch_size = 5 # every how many episodes to do a param update?\n",
    "learning_rate = 1e-2 # feel free to play with this to train faster or more stably.\n",
    "gamma = 0.99 # discount factor for reward\n",
    "\n",
    "D = observation.features.head().shape[1] # input dimensionality\n",
    "H = int(D / 3) # number of hidden layer neurons\n",
    "\n",
    "[D, H]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "#This defines the network as it goes from taking an observation of the environment to \n",
    "#giving a probability of chosing to the action of moving left or right.\n",
    "observations = tf.placeholder(tf.float32, [None,D] , name=\"input_x\")\n",
    "W1 = tf.get_variable(\"W1\", shape=[D, H],\n",
    "           initializer=tf.contrib.layers.xavier_initializer())\n",
    "layer1 = tf.nn.relu(tf.matmul(observations,W1))\n",
    "W2 = tf.get_variable(\"W2\", shape=[H, 1],\n",
    "           initializer=tf.contrib.layers.xavier_initializer())\n",
    "score = tf.matmul(layer1,W2)\n",
    "probability = tf.nn.sigmoid(score)\n",
    "\n",
    "#From here we define the parts of the network needed for learning a good policy.\n",
    "tvars = tf.trainable_variables()\n",
    "input_y = tf.placeholder(tf.float32,[None,1], name=\"input_y\")\n",
    "advantages = tf.placeholder(tf.float32,name=\"reward_signal\")\n",
    "\n",
    "# The loss function. This sends the weights in the direction of making actions \n",
    "# that gave good advantage (reward over time) more likely, and actions that didn't less likely.\n",
    "#TODO fix loglik = tf.log(input_y*(input_y - probability) + (1 - input_y)*(input_y + probability))\n",
    "loglik = (input_y - probability)\n",
    "loss = -tf.reduce_mean(loglik * advantages) \n",
    "newGrads = tf.gradients(loss,tvars)\n",
    "\n",
    "# Once we have collected a series of gradients from multiple episodes, we apply them.\n",
    "# We don't just apply gradeients after every episode in order to account for noise in the reward signal.\n",
    "adam = tf.train.AdamOptimizer(learning_rate=learning_rate) # Our optimizer\n",
    "# Placeholders to send the final gradients through when we update.\n",
    "W1Grad = tf.placeholder(tf.float32,name=\"batch_grad1\") \n",
    "W2Grad = tf.placeholder(tf.float32,name=\"batch_grad2\")\n",
    "#\n",
    "batchGrad = [W1Grad,W2Grad]\n",
    "updateGrads = adam.apply_gradients(zip(batchGrad,tvars))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def discount_rewards(r):\n",
    "    \"\"\" take 1D float array of rewards and compute discounted reward \"\"\"\n",
    "    discounted_r = np.zeros_like(r)\n",
    "    running_add = 0\n",
    "    # in Python 2:\n",
    "    # for t in reversed(xrange(0, r.size)):\n",
    "    for t in reversed(range(0, r.shape[0])):\n",
    "        running_add = running_add * gamma + r[t]\n",
    "        discounted_r[t] = running_add\n",
    "    return discounted_r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Debug:\n",
    "    def __init__(self, state):\n",
    "        self.state = state\n",
    "\n",
    "    def log(self, msg):\n",
    "        if self.state % 1 == 0:\n",
    "            print(msg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>derived_0</th>\n",
       "      <th>derived_1</th>\n",
       "      <th>derived_2</th>\n",
       "      <th>derived_3</th>\n",
       "      <th>derived_4</th>\n",
       "      <th>fundamental_0</th>\n",
       "      <th>fundamental_1</th>\n",
       "      <th>fundamental_2</th>\n",
       "      <th>...</th>\n",
       "      <th>technical_36</th>\n",
       "      <th>technical_37</th>\n",
       "      <th>technical_38</th>\n",
       "      <th>technical_39</th>\n",
       "      <th>technical_40</th>\n",
       "      <th>technical_41</th>\n",
       "      <th>technical_42</th>\n",
       "      <th>technical_43</th>\n",
       "      <th>technical_44</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.370326</td>\n",
       "      <td>-0.006316</td>\n",
       "      <td>0.222831</td>\n",
       "      <td>-0.213030</td>\n",
       "      <td>0.729277</td>\n",
       "      <td>-0.335633</td>\n",
       "      <td>0.113292</td>\n",
       "      <td>1.621238</td>\n",
       "      <td>...</td>\n",
       "      <td>0.775208</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.414776</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.011753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0.014765</td>\n",
       "      <td>-0.038064</td>\n",
       "      <td>-0.017425</td>\n",
       "      <td>0.320652</td>\n",
       "      <td>-0.034134</td>\n",
       "      <td>0.004413</td>\n",
       "      <td>0.114285</td>\n",
       "      <td>-0.210185</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025590</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.273607</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.001240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.010622</td>\n",
       "      <td>-0.050577</td>\n",
       "      <td>3.379575</td>\n",
       "      <td>-0.157525</td>\n",
       "      <td>-0.068550</td>\n",
       "      <td>-0.155937</td>\n",
       "      <td>1.219439</td>\n",
       "      <td>-0.764516</td>\n",
       "      <td>...</td>\n",
       "      <td>0.151881</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.175710</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.020940</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 111 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  timestamp  derived_0  derived_1  derived_2  derived_3  derived_4  \\\n",
       "0  10          0   0.370326  -0.006316   0.222831  -0.213030   0.729277   \n",
       "1  11          0   0.014765  -0.038064  -0.017425   0.320652  -0.034134   \n",
       "2  12          0  -0.010622  -0.050577   3.379575  -0.157525  -0.068550   \n",
       "\n",
       "   fundamental_0  fundamental_1  fundamental_2    ...     technical_36  \\\n",
       "0      -0.335633       0.113292       1.621238    ...         0.775208   \n",
       "1       0.004413       0.114285      -0.210185    ...         0.025590   \n",
       "2      -0.155937       1.219439      -0.764516    ...         0.151881   \n",
       "\n",
       "   technical_37  technical_38  technical_39  technical_40  technical_41  \\\n",
       "0           NaN           NaN           NaN     -0.414776           NaN   \n",
       "1           NaN           NaN           NaN     -0.273607           NaN   \n",
       "2           NaN           NaN           NaN     -0.175710           NaN   \n",
       "\n",
       "   technical_42  technical_43  technical_44         y  \n",
       "0           NaN          -2.0           NaN -0.011753  \n",
       "1           NaN          -2.0           NaN -0.001240  \n",
       "2           NaN          -2.0           NaN -0.020940  \n",
       "\n",
       "[3 rows x 111 columns]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here's an example of loading the CSV using Pandas's built-in HDF5 support:\n",
    "import pandas as pd\n",
    "\n",
    "with pd.HDFStore(\"../input/train.h5\", \"r\") as train:\n",
    "    # Note that the \"train\" dataframe is the only dataframe in the file\n",
    "    df = train.get(\"train\")\n",
    "\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gradBuffer 2 110 36\n",
      "       id  timestamp  derived_0  derived_1  derived_2  derived_3  derived_4  \\\n",
      "965  2154        907   0.073150  -0.015944   0.292708   0.335373    0.04207   \n",
      "966  2155        907   0.019957  -0.053259   0.000000  -0.010258    0.00000   \n",
      "967  2156        907  -0.011181  -0.047295   0.000000   0.079977    0.00000   \n",
      "\n",
      "     fundamental_0  fundamental_1  fundamental_2      ...       technical_35  \\\n",
      "965      -0.228946       0.176791      -0.157165      ...          -0.057939   \n",
      "966      -0.095227      -0.095520       0.000000      ...           0.157331   \n",
      "967       0.303686       0.230367       0.000000      ...          -0.221998   \n",
      "\n",
      "     technical_36  technical_37  technical_38  technical_39  technical_40  \\\n",
      "965      0.116224 -7.629580e-01 -2.924564e-15 -7.629580e-01      0.073505   \n",
      "966      0.018996 -6.040228e-04 -6.040228e-04 -6.040228e-04     -0.073433   \n",
      "967     -0.304919 -1.677802e-16 -1.677802e-16 -1.677802e-16      0.069225   \n",
      "\n",
      "     technical_41  technical_42  technical_43  technical_44  \n",
      "965     -0.181965 -1.295806e-02 -2.720471e-02     -0.054803  \n",
      "966      0.197530 -1.391867e-26 -3.330669e-16     -0.011410  \n",
      "967     -0.001489  7.500000e-01 -2.000000e+00     -0.001317  \n",
      "\n",
      "[3 rows x 110 columns]\n",
      "\\Timestamp #907\n",
      "Action is (968, 2)        id    y\n",
      "965  2154  0.0\n",
      "966  2155  0.0\n",
      "967  2156  0.0\n",
      "len(Y)=968\n",
      "observation.shape=(968, 2)\n",
      "       id    y\n",
      "965  2154  0.5\n",
      "966  2155  0.5\n",
      "967  2156  0.5\n",
      "Reward is -1\n",
      "Perfect action 965   -0.003014\n",
      "966   -0.005051\n",
      "967   -0.002818\n",
      "Name: y, dtype: float32\n",
      "Rewards .shape 968\n",
      "Set epy to perfect action\n",
      "Skip repeated timestamp 907\n",
      "         id    y\n",
      "966  2155.0  1.0\n",
      "967  2156.0  1.0\n",
      "968     0.0  0.5\n",
      "len(Y)=968\n",
      "observation.shape=(968, 2)\n",
      "       id  timestamp  derived_0  derived_1  derived_2  derived_3  derived_4  \\\n",
      "965  2154        908   0.073973  -0.015643   0.292351   0.339723   0.043281   \n",
      "966  2155        908   0.020194  -0.053125   0.000000  -0.012847   0.000000   \n",
      "967  2156        908  -0.010510  -0.047317   0.000000   0.083736   0.000000   \n",
      "\n",
      "     fundamental_0  fundamental_1  fundamental_2      ...       technical_35  \\\n",
      "965      -0.228957       0.178557      -0.157204      ...          -0.060028   \n",
      "966      -0.095269      -0.096527       0.000000      ...           0.156530   \n",
      "967       0.305819       0.229999       0.000000      ...          -0.220242   \n",
      "\n",
      "     technical_36  technical_37  technical_38  technical_39  technical_40  \\\n",
      "965      0.128807 -8.203558e-01 -2.216405e-15 -8.203558e-01      0.071724   \n",
      "966      0.018461 -4.577637e-04 -4.577637e-04 -4.577637e-04     -0.074643   \n",
      "967     -0.302415 -1.271536e-16 -1.271536e-16 -1.271536e-16      0.072781   \n",
      "\n",
      "     technical_41  technical_42  technical_43  technical_44  \n",
      "965     -0.179831 -9.820375e-03 -2.061731e-02     -0.047551  \n",
      "966      0.196070 -1.054838e-26 -3.330669e-16     -0.011827  \n",
      "967     -0.004073  8.105354e-01 -2.000000e+00      0.000525  \n",
      "\n",
      "[3 rows x 110 columns]\n",
      "\\Timestamp #908\n",
      "Action is (968, 2)        id    y\n",
      "965  2154  0.5\n",
      "966  2155  0.5\n",
      "967  2156  0.5\n",
      "len(Y)=968\n",
      "observation.shape=(968, 2)\n",
      "       id    y\n",
      "965  2154  0.5\n",
      "966  2155  0.5\n",
      "967  2156  0.5\n",
      "Reward is -1\n",
      "Perfect action 965    0.003881\n",
      "966    0.003910\n",
      "967   -0.007010\n",
      "Name: y, dtype: float32\n",
      "Rewards .shape 968\n",
      "Set epy to perfect action\n",
      "       id  timestamp  derived_0  derived_1  derived_2  derived_3  derived_4  \\\n",
      "965  2154        909   0.074306  -0.015520   0.292206   0.341485   0.043772   \n",
      "966  2155        909   0.020290  -0.053071   0.000000  -0.013896   0.000000   \n",
      "967  2156        909  -0.010239  -0.047325   0.000000   0.085259   0.000000   \n",
      "\n",
      "     fundamental_0  fundamental_1  fundamental_2      ...       technical_35  \\\n",
      "965      -0.228961       0.179273       -0.15722      ...          -0.060874   \n",
      "966      -0.095286      -0.096935        0.00000      ...           0.156205   \n",
      "967       0.306684       0.229850        0.00000      ...          -0.219530   \n",
      "\n",
      "     technical_36  technical_37  technical_38  technical_39  technical_40  \\\n",
      "965      0.133905 -8.436106e-01 -1.929493e-15 -8.436106e-01      0.071003   \n",
      "966      0.018244 -3.985064e-04 -3.985064e-04 -3.985064e-04     -0.075133   \n",
      "967     -0.301400 -1.106936e-16 -1.106936e-16 -1.106936e-16      0.074222   \n",
      "\n",
      "     technical_41  technical_42  technical_43  technical_44  \n",
      "965     -0.140588 -8.549132e-03 -1.794841e-02     -0.049238  \n",
      "966      0.219594 -9.182896e-27 -3.330669e-16     -0.004353  \n",
      "967      0.008187  8.350615e-01 -2.000000e+00      0.002113  \n",
      "\n",
      "[3 rows x 110 columns]\n",
      "\\Timestamp #909\n",
      "Action is (968, 2)        id    y\n",
      "965  2154  0.5\n",
      "966  2155  0.5\n",
      "967  2156  0.5\n",
      "len(Y)=968\n",
      "observation.shape=(967, 2)\n",
      "         id    y\n",
      "965  2155.0  0.0\n",
      "966  2156.0  0.0\n",
      "967     0.0  0.0\n",
      "Reward is -1\n",
      "Perfect action           0    1    2    3    4    5    6    7    8    9   ...   957  958  \\\n",
      "965 -0.002657  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN ...   NaN  NaN   \n",
      "966 -0.005547  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN ...   NaN  NaN   \n",
      "967  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...   0.0  0.0   \n",
      "\n",
      "     959  960  961  962  963  964  965  966  \n",
      "965  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
      "966  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
      "967  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "\n",
      "[3 rows x 967 columns]\n",
      "Rewards .shape 968\n",
      "Skip repeated timestamp 909\n",
      "         id    y\n",
      "966  2155.0  1.0\n",
      "967  2156.0  1.0\n",
      "968     0.0  0.5\n",
      "len(Y)=968\n",
      "observation.shape=(967, 2)\n",
      "Skip repeated timestamp 909\n",
      "         id    y\n",
      "966  2155.0  1.0\n",
      "967  2156.0  1.0\n",
      "968     0.0  0.5\n",
      "len(Y)=968\n",
      "observation.shape=(967, 2)\n",
      "     derived_0  derived_1  derived_2  derived_3  derived_4  fundamental_0  \\\n",
      "965   0.020564  -0.052916        0.0  -0.016899        0.0      -0.095334   \n",
      "966  -0.009461  -0.047350        0.0   0.089618        0.0       0.309158   \n",
      "967   0.000000   0.000000        0.0   0.000000        0.0       0.000000   \n",
      "\n",
      "     fundamental_1  fundamental_10  fundamental_11  fundamental_12    ...      \\\n",
      "965      -0.098103       -0.039845             0.0       -0.005437    ...       \n",
      "966       0.229423       -0.030083             0.0       -0.017730    ...       \n",
      "967       0.000000        0.000000             0.0        0.000000    ...       \n",
      "\n",
      "     technical_40  technical_41  technical_42  technical_43  technical_44  \\\n",
      "965     -0.076535      0.215496 -5.274188e-27 -3.330669e-16      0.002578   \n",
      "966      0.078347      0.016536  9.052677e-01 -2.000000e+00      0.001154   \n",
      "967      0.000000      0.000000  0.000000e+00  0.000000e+00      0.000000   \n",
      "\n",
      "     technical_5  technical_6  technical_7   technical_9  timestamp  \n",
      "965     0.013878    -0.000001    -0.292853  0.000000e+00      912.0  \n",
      "966     0.028090    -0.189465    -0.276782 -6.074524e-17      912.0  \n",
      "967     0.000000     0.000000     0.000000  0.000000e+00        0.0  \n",
      "\n",
      "[3 rows x 110 columns]\n",
      "\\Timestamp #912.0\n",
      "Action is (968, 2)          id    y\n",
      "965  2155.0  0.0\n",
      "966  2156.0  0.0\n",
      "967     0.0  0.0\n",
      "len(Y)=968\n",
      "observation.shape=(967, 2)\n",
      "         id    y\n",
      "965  2155.0  0.0\n",
      "966  2156.0  0.0\n",
      "967     0.0  0.0\n",
      "Reward is -0.34917844392279945\n",
      "Perfect action           0    1    2    3    4    5    6    7    8    9   ...   957  958  \\\n",
      "965 -0.002183  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN ...   NaN  NaN   \n",
      "966 -0.003382  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN ...   NaN  NaN   \n",
      "967  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...   0.0  0.0   \n",
      "\n",
      "     959  960  961  962  963  964  965  966  \n",
      "965  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
      "966  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
      "967  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "\n",
      "[3 rows x 967 columns]\n",
      "Rewards .shape 968\n",
      "Set epy to perfect action\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Incompatible shapes: [967,1] vs. [968,1]\n\t [[Node: sub = Sub[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_recv_input_y_0, Sigmoid)]]\n\nCaused by op 'sub', defined at:\n  File \"/opt/conda/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/opt/conda/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/opt/conda/lib/python3.5/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/opt/conda/lib/python3.5/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/opt/conda/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"/opt/conda/lib/python3.5/site-packages/zmq/eventloop/ioloop.py\", line 162, in start\n    super(ZMQIOLoop, self).start()\n  File \"/opt/conda/lib/python3.5/site-packages/tornado/ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"/opt/conda/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/opt/conda/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/opt/conda/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/opt/conda/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/opt/conda/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/opt/conda/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/opt/conda/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/opt/conda/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"/opt/conda/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/opt/conda/lib/python3.5/site-packages/ipykernel/zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/opt/conda/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/opt/conda/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/opt/conda/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-81-e5207613f1a8>\", line 24, in <module>\n    loglik = (input_y - probability)\n  File \"/opt/conda/lib/python3.5/site-packages/tensorflow/python/ops/math_ops.py\", line 814, in binary_op_wrapper\n    return func(x, y, name=name)\n  File \"/opt/conda/lib/python3.5/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 2758, in sub\n    result = _op_def_lib.apply_op(\"Sub\", x=x, y=y, name=name)\n  File \"/opt/conda/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 759, in apply_op\n    op_def=op_def)\n  File \"/opt/conda/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2240, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/opt/conda/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1128, in __init__\n    self._traceback = _extract_stack()\n\nInvalidArgumentError (see above for traceback): Incompatible shapes: [967,1] vs. [968,1]\n\t [[Node: sub = Sub[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_recv_input_y_0, Sigmoid)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1020\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1022\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1002\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1003\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1004\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[0;34m()\u001b[0m\n\u001b[1;32m    468\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 469\u001b[0;31m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[1;32m    470\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Incompatible shapes: [967,1] vs. [968,1]\n\t [[Node: sub = Sub[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_recv_input_y_0, Sigmoid)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-132-c8c8e22047a7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0mdiscounted_epr\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiscounted_epr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0;31m# Get the gradient for this episode, and save it in the gradBuffer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m         \u001b[0mtGrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnewGrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mobservations\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_y\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mepy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madvantages\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdiscounted_epr\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtGrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m             \u001b[0;31m#debug.log(\"grad-{0} is {1}\".format(str(ix), grad))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 766\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    767\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    962\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 964\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    965\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    966\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1014\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1015\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1032\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1034\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1035\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Incompatible shapes: [967,1] vs. [968,1]\n\t [[Node: sub = Sub[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_recv_input_y_0, Sigmoid)]]\n\nCaused by op 'sub', defined at:\n  File \"/opt/conda/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/opt/conda/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/opt/conda/lib/python3.5/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/opt/conda/lib/python3.5/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/opt/conda/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"/opt/conda/lib/python3.5/site-packages/zmq/eventloop/ioloop.py\", line 162, in start\n    super(ZMQIOLoop, self).start()\n  File \"/opt/conda/lib/python3.5/site-packages/tornado/ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"/opt/conda/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/opt/conda/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/opt/conda/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/opt/conda/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/opt/conda/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/opt/conda/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/opt/conda/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/opt/conda/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"/opt/conda/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/opt/conda/lib/python3.5/site-packages/ipykernel/zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/opt/conda/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/opt/conda/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/opt/conda/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-81-e5207613f1a8>\", line 24, in <module>\n    loglik = (input_y - probability)\n  File \"/opt/conda/lib/python3.5/site-packages/tensorflow/python/ops/math_ops.py\", line 814, in binary_op_wrapper\n    return func(x, y, name=name)\n  File \"/opt/conda/lib/python3.5/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 2758, in sub\n    result = _op_def_lib.apply_op(\"Sub\", x=x, y=y, name=name)\n  File \"/opt/conda/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 759, in apply_op\n    op_def=op_def)\n  File \"/opt/conda/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2240, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/opt/conda/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1128, in __init__\n    self._traceback = _extract_stack()\n\nInvalidArgumentError (see above for traceback): Incompatible shapes: [967,1] vs. [968,1]\n\t [[Node: sub = Sub[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_recv_input_y_0, Sigmoid)]]\n"
     ]
    }
   ],
   "source": [
    "# Create environment\n",
    "env = kagglegym.make()\n",
    "# Get first observation\n",
    "observation = env.reset()\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "\n",
    "def extend(x):\n",
    "    if x.shape[0] > 967:\n",
    "        return x\n",
    "    keys = list(x.keys())\n",
    "    zeros = [.0] * len(keys)\n",
    "    tail = pd.DataFrame(dict(zip(keys, zeros)), index=[967])\n",
    "    x = pd.concat([x, tail])\n",
    "    return x\n",
    "\n",
    "class State:\n",
    "    def __init__(self, observation, reward = .0, done = False, info = {}, y = []):\n",
    "        self.observation = observation\n",
    "        self.action = observation.target\n",
    "        self.reward = reward\n",
    "        self.done = done\n",
    "        self.info = info\n",
    "        self.y = y\n",
    "    \n",
    "    @property\n",
    "    def y(self):\n",
    "        return self.action[\"y\"];\n",
    "\n",
    "    @y.setter\n",
    "    def y(self, y):\n",
    "        rows = self.action.shape[0]\n",
    "        self.action[\"y\"] = y if len(y) == rows else [.0] * rows\n",
    "        self.action = extend(self.action)        \n",
    "\n",
    "class Agent:\n",
    "    def __init__(self, sess, env):\n",
    "        self.sess = sess\n",
    "        self.env = env\n",
    "    \n",
    "    def step(self, state, debug = Debug(-1)):\n",
    "        observation = state.observation\n",
    "        x = observation.features\n",
    "        x = extend(x)\n",
    "        # Run the policy network and get an action to take. \n",
    "        y = self.sess.run(probability,feed_dict={observations: x})\n",
    "        debug.log(\"len(Y)={}\".format(len(y)))\n",
    "        state.y = y\n",
    "        # step the environment and get new measurements\n",
    "        if observation.target.shape[0] == state.y.shape[0]:\n",
    "            observation, reward, done, info = self.env.step(state.action)\n",
    "        else:\n",
    "            observation, reward, done, info = self.env.step(observation.target)\n",
    "        debug.log(\"observation.shape={}\".format(observation.target.shape))\n",
    "        return State(observation, reward, done, info, y)\n",
    "        \n",
    "        \n",
    "timestamp = -1\n",
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    rendering = False\n",
    "    sess.run(init)\n",
    "    observation = env.reset() # Obtain an initial observation of the environment\n",
    "\n",
    "    # Reset the gradient placeholder. We will collect gradients in \n",
    "    # gradBuffer until we are ready to update our policy network. \n",
    "    gradBuffer = sess.run(tvars)\n",
    "    for ix,grad in enumerate(gradBuffer):\n",
    "        gradBuffer[ix] = grad * 0\n",
    "    print(\"gradBuffer\", len(gradBuffer), len(gradBuffer[0]), len(gradBuffer[1]))\n",
    "    \n",
    "    rewards = []\n",
    "    done = False\n",
    "    epy = []\n",
    "    agent = Agent(sess, env)\n",
    "    state = State(observation, reward)\n",
    "    while not done:\n",
    "        x = state.observation.features.head(968)\n",
    "        x = x.fillna(.0)\n",
    "        x = extend(x)\n",
    "        # log\n",
    "        t = x[\"timestamp\"][0]\n",
    "        if timestamp == t or t == 910 or t == 911:\n",
    "            print(\"Skip repeated timestamp {}\".format(timestamp))\n",
    "            debug.log(action.tail(3))\n",
    "            # step the environment and get new measurements\n",
    "            state = agent.step(state)\n",
    "            continue\n",
    "            \n",
    "        timestamp = x[\"timestamp\"][0]\n",
    "        #timestamp = 0\n",
    "        debug = Debug(timestamp)\n",
    "        debug.log(x.tail(3))\n",
    "        debug.log(\"\\Timestamp #{}\".format(timestamp))\n",
    "\n",
    "        debug.log(\"Action is {0} {1}\".format(state.action.shape, state.action.tail(3)))\n",
    "        state = agent.step(state)\n",
    "        # log\n",
    "        debug.log(state.action.tail(3))\n",
    "        debug.log(\"Reward is {}\".format(state.reward))\n",
    "        \n",
    "        # record reward (has to be done after we call step() to get reward for previous action)\n",
    "        perfect_action = df[df[\"timestamp\"] == state.observation.features[\"timestamp\"][0]][[\"id\", \"y\"]] \\\n",
    "            .reset_index(drop=True)\n",
    "        pa = perfect_action[\"y\"].head(968)\n",
    "        pa = pa.fillna(.0)\n",
    "        pa = extend(pa)\n",
    "        # extend to 968\n",
    "        #for i in range(pa.shape[0]+1, 969):\n",
    "        #    pa = pa.append(pd.Series(.0, index=[i]))\n",
    "        #pa = np.nan_to_num(perfect_action[\"y\"])\n",
    "                \n",
    "        y = state.action[\"y\"]\n",
    "        debug.log(\"Perfect action {}\".format(pa.tail(3)))\n",
    "        rewards = pa - y.fillna(.0)\n",
    "        rewards = -np.abs(rewards) #* 10\n",
    "        rewards = np.nan_to_num(rewards)\n",
    "        debug.log(\"Rewards .shape {}\".format(len(rewards)))\n",
    "        #rewards = np.vstack(rewards)\n",
    "        \n",
    "        if len(epy) == 0 or y.equals(epy): # protect gradients\n",
    "            print(\"Set epy to perfect action\")\n",
    "            epy = pa\n",
    "            \n",
    "        epy = np.vstack(epy)\n",
    "        # compute the discounted reward backwards through time\n",
    "        discounted_epr = discount_rewards(rewards)\n",
    "        # size the rewards to be unit normal (helps control the gradient estimator variance)\n",
    "        discounted_epr -= np.mean(discounted_epr)\n",
    "        discounted_epr /= np.std(discounted_epr)\n",
    "        # Get the gradient for this episode, and save it in the gradBuffer\n",
    "        tGrad = sess.run(newGrads,feed_dict={observations: x, input_y: epy, advantages: discounted_epr})\n",
    "        for ix,grad in enumerate(tGrad):\n",
    "            #debug.log(\"grad-{0} is {1}\".format(str(ix), grad))\n",
    "            gradBuffer[ix] += grad\n",
    "        \n",
    "        # If we have completed enough episodes, then update the policy network with our gradients.\n",
    "        sess.run(updateGrads,feed_dict={W1Grad: gradBuffer[0],W2Grad:gradBuffer[1]})\n",
    "        for ix,grad in enumerate(gradBuffer):\n",
    "            gradBuffer[ix] = grad * 0\n",
    "\n",
    "        epy = y\n",
    "    \n",
    "        if timestamp > 910:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestamp #1000\n",
      "Timestamp #1100\n",
      "Timestamp #1200\n",
      "Timestamp #1300\n",
      "Timestamp #1400\n",
      "Timestamp #1500\n",
      "Timestamp #1600\n",
      "Timestamp #1700\n",
      "Timestamp #1800\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'public_score': -0.0083462397338969572}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = kagglegym.make()\n",
    "observation = env.reset()\n",
    "\n",
    "while True:\n",
    "    target = observation.target\n",
    "    timestamp = observation.features[\"timestamp\"][0]\n",
    "    if timestamp % 100 == 0:\n",
    "        print(\"Timestamp #{}\".format(timestamp))\n",
    "\n",
    "    observation, reward, done, info = env.step(target)\n",
    "    if done:        \n",
    "        break\n",
    "        \n",
    "info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow.contrib.slim as slim\n",
    "\n",
    "class agent():\n",
    "    def __init__(self, lr, s_size,a_size,h_size):\n",
    "        #These lines established the feed-forward part of the network. The agent takes a state and produces an action.\n",
    "        self.state_in= tf.placeholder(shape=[None,s_size],dtype=tf.float32)\n",
    "        hidden = slim.fully_connected(self.state_in,h_size,biases_initializer=None,activation_fn=tf.nn.relu)\n",
    "        self.output = slim.fully_connected(hidden,a_size,activation_fn=tf.nn.softmax,biases_initializer=None)\n",
    "        self.chosen_action = tf.argmax(self.output,1)\n",
    "\n",
    "        #The next six lines establish the training proceedure. We feed the reward and chosen action into the network\n",
    "        #to compute the loss, and use it to update the network.\n",
    "        self.reward_holder = tf.placeholder(shape=[None],dtype=tf.float32)\n",
    "        self.action_holder = tf.placeholder(shape=[None],dtype=tf.int32)\n",
    "        \n",
    "        self.indexes = tf.range(0, tf.shape(self.output)[0]) * tf.shape(self.output)[1] + self.action_holder\n",
    "        self.responsible_outputs = tf.gather(tf.reshape(self.output, [-1]), self.indexes)\n",
    "\n",
    "        self.loss = -tf.reduce_mean(tf.log(self.responsible_outputs)*self.reward_holder)\n",
    "        \n",
    "        tvars = tf.trainable_variables()\n",
    "        self.gradient_holders = []\n",
    "        for idx,var in enumerate(tvars):\n",
    "            placeholder = tf.placeholder(tf.float32,name=str(idx)+'_holder')\n",
    "            self.gradient_holders.append(placeholder)\n",
    "        \n",
    "        self.gradients = tf.gradients(self.loss,tvars)\n",
    "        \n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=lr)\n",
    "        self.update_batch = optimizer.apply_gradients(zip(self.gradient_holders,tvars))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.5/site-packages/tensorflow/python/ops/gradients_impl.py:91: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    }
   ],
   "source": [
    "# TODO implement arbitrary actions from https://github.com/awjuliani/DeepRL-Agents/blob/master/Vanilla-Policy.ipynb\n",
    "\n",
    "tf.reset_default_graph() #Clear the Tensorflow graph.\n",
    "myAgent = agent(lr=1e-2,s_size=4,a_size=2,h_size=8) #Load the agent.\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
