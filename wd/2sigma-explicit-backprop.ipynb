{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features = 110 #784\n",
    "classes = 1 #10\n",
    "\n",
    "a_0 = tf.placeholder(tf.float32, [None, features])\n",
    "y = tf.placeholder(tf.float32, [None, classes])\n",
    "\n",
    "middle = 20 #int(features / 3)\n",
    "w_1 = tf.Variable(tf.truncated_normal([features, middle]))\n",
    "b_1 = tf.Variable(tf.truncated_normal([1, middle]))\n",
    "w_2 = tf.Variable(tf.truncated_normal([middle, classes]))\n",
    "b_2 = tf.Variable(tf.truncated_normal([1, classes]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigma(x):\n",
    "    return tf.div(tf.constant(1.0),\n",
    "                  tf.add(tf.constant(1.0), tf.exp(tf.neg(x))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "z_1 = tf.add(tf.matmul(a_0, w_1), b_1)\n",
    "a_1 = sigma(z_1)\n",
    "z_2 = tf.add(tf.matmul(a_1, w_2), b_2)\n",
    "a_2 = sigma(z_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "diff = tf.sub(a_2, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sigmoid Derivative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmaprime(x):\n",
    "    return tf.mul(sigma(x), tf.sub(tf.constant(1.0), sigma(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Back Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d_z_2 = tf.mul(diff, sigmaprime(z_2))\n",
    "d_b_2 = d_z_2\n",
    "d_w_2 = tf.matmul(tf.transpose(a_1), d_z_2)\n",
    "\n",
    "d_a_1 = tf.matmul(d_z_2, tf.transpose(w_2))\n",
    "d_z_1 = tf.mul(d_a_1, sigmaprime(z_1))\n",
    "d_b_1 = d_z_1\n",
    "d_w_1 = tf.matmul(tf.transpose(a_0), d_z_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eta = tf.constant(0.5)\n",
    "step = [\n",
    "    tf.assign(w_1,\n",
    "            tf.sub(w_1, tf.mul(eta, d_w_1)))\n",
    "  , tf.assign(b_1,\n",
    "            tf.sub(b_1, tf.mul(eta,\n",
    "                               tf.reduce_mean(d_b_1, reduction_indices=[0]))))\n",
    "  , tf.assign(w_2,\n",
    "            tf.sub(w_2, tf.mul(eta, d_w_2)))\n",
    "  , tf.assign(b_2,\n",
    "            tf.sub(b_2, tf.mul(eta,\n",
    "                               tf.reduce_mean(d_b_2, reduction_indices=[0]))))\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 Sigma Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "acct_mat = tf.equal(tf.argmax(a_2, 1), tf.argmax(y, 1))\n",
    "acct_res = tf.reduce_sum(tf.cast(acct_mat, tf.float32))\n",
    "\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #0, Timestamp #1000, Reward -0.009768245129833153\n",
      "Epoch #0, Timestamp #1100, Reward -0.0784853453190204\n",
      "Epoch #0, Timestamp #1200, Reward -0.06722142736796209\n",
      "Epoch #0, Timestamp #1300, Reward -0.03831479699670408\n",
      "Epoch #0, Timestamp #1400, Reward -0.16841577420002168\n",
      "Epoch #0, Timestamp #1500, Reward -0.16337528218121475\n",
      "Epoch #0, Timestamp #1600, Reward -0.16900778147536097\n",
      "Epoch #0, Timestamp #1700, Reward -0.025669278916603158\n",
      "Epoch #0, Timestamp #1800, Reward -0.054221471311693206\n",
      "Epoch #1, Timestamp #1000, Reward -0.009768245129833153\n",
      "Epoch #1, Timestamp #1100, Reward -0.0784853453190204\n",
      "Epoch #1, Timestamp #1200, Reward -0.06722142736796209\n",
      "Epoch #1, Timestamp #1300, Reward -0.03831479699670408\n",
      "Epoch #1, Timestamp #1400, Reward -0.16841577420002168\n",
      "Epoch #1, Timestamp #1500, Reward -0.16337528218121475\n",
      "Epoch #1, Timestamp #1600, Reward -0.16900778147536097\n",
      "Epoch #1, Timestamp #1700, Reward -0.025669278916603158\n",
      "Epoch #1, Timestamp #1800, Reward -0.054221471311693206\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'public_score': -0.0083462397338969572}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import kagglegym\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    for epoch in range(0, 2):\n",
    "        env = kagglegym.make()\n",
    "        observation = env.reset()\n",
    "\n",
    "        done = False\n",
    "        while not done:\n",
    "            target = observation.target\n",
    "            timestamp = observation.features[\"timestamp\"][0]\n",
    "\n",
    "            batch_xs = observation.features.fillna(0)\n",
    "            target[\"y\"] = sess.run(a_2, feed_dict = {a_0: batch_xs})\n",
    "            #print(target[\"y\"])\n",
    "\n",
    "            observation, reward, done, info = env.step(target)\n",
    "\n",
    "            batch_ys = np.vstack([reward] * classes)\n",
    "            sess.run(step, feed_dict = {a_0: batch_xs,\n",
    "                                        y : batch_ys})\n",
    "\n",
    "            if timestamp % 100 == 0:\n",
    "                print(\"Epoch #{0}, Timestamp #{1}, Reward {2}\".format(epoch, timestamp, reward))\n",
    "                #break\n",
    "\n",
    "        \n",
    "info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 784\n",
      "124.0\n",
      "10 784\n",
      "743.0\n",
      "10 784\n",
      "783.0\n",
      "10 784\n",
      "805.0\n",
      "10 784\n",
      "798.0\n",
      "10 784\n",
      "818.0\n",
      "10 784\n",
      "809.0\n",
      "10 784\n",
      "816.0\n",
      "10 784\n",
      "833.0\n",
      "10 784\n",
      "914.0\n"
     ]
    }
   ],
   "source": [
    "acct_mat = tf.equal(tf.argmax(a_2, 1), tf.argmax(y, 1))\n",
    "acct_res = tf.reduce_sum(tf.cast(acct_mat, tf.float32))\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "for i in range(10000):\n",
    "    batch_xs, batch_ys = mnist.train.next_batch(10)\n",
    "    sess.run(step, feed_dict = {a_0: batch_xs,\n",
    "                                y : batch_ys})\n",
    "    if i % 1000 == 0:\n",
    "        print(len(batch_xs), len(batch_xs[0]))\n",
    "        res = sess.run(acct_res, feed_dict =\n",
    "                       {a_0: mnist.test.images[:1000],\n",
    "                        y : mnist.test.labels[:1000]})\n",
    "        print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
